{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A Short Introduction to the Pandas Package"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Pandas` is the Python Data Analysis Library from the makers of `scipy`, `numpy`, and `IPython`.  It provides the perfect data structures for textual matrices, the`Series` and the `DataFrame`.  Let's jump right in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd #the recommended import condition from pandas\n",
      "import numpy as np\n",
      "sentence = 'the dog bit the man' #our first sentence from the presentation\n",
      "token_list = sentence.split()\n",
      "type_list = list(set(token_list)) #we only want each word type listed once\n",
      "print(type_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's initialize a `Series` with these index labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser1 = pd.Series(index = type_list)\n",
      "print(ser1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to initialize it with values, we can add do this with the `data` argument or with a dictionary.  First, let's get the counts for each word in the sentence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_list = []\n",
      "count_dict = {}\n",
      "for word in type_list:\n",
      "    count_list.append(token_list.count(word))\n",
      "    count_dict[word] = token_list.count(word)\n",
      "print(count_list)\n",
      "print(type_list)\n",
      "print(count_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can create our `Series` objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser2 = pd.Series(data = count_list, index = type_list)\n",
      "ser3 = pd.Series(count_dict)\n",
      "print(ser2)\n",
      "print(ser3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A `Series` is essentially a labelled vector, here a frequency term-document vector.  In order to construct a term-document matrix, we can create another `Series` for our second sentence..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent2 = 'the bat hit the ball'\n",
      "tok_list2 = sent2.split()\n",
      "type_list2 = list(set(tok_list2))\n",
      "count_dict2 = {}\n",
      "for word in type_list2:\n",
      "    count_dict2[word] = tok_list2.count(word)\n",
      "ser4 = pd.Series(count_dict2)\n",
      "print(ser4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and then put them both together."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1 = pd.DataFrame(data = [ser3, ser4], index = ['sent1', 'sent2'])\n",
      "print(df1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could also create the `DataFrame` by calling our `count_dict`s directly.  In this `DataFrame`, let's replace all nan values with 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = pd.DataFrame(data = [count_dict, count_dict2], index = ['sent1', 'sent2'])\n",
      "print(df2)\n",
      "df2 = df2.fillna(value = 0)\n",
      "print(df2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don't worry about the fact that the rows and columns are switched here.  When you perform actions on the `DataFrame`, you can tell Pandas whether to perform it on rows or columns. </br>And now we can call values simply by naming the row, column name pairs.  Name the row first, then the column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df1.ix['sent1', 'ball'])\n",
      "print(df1.loc['sent1', 'ball'])\n",
      "print(df1.ix['sent2', 'ball'])\n",
      "print(df2.ix['sent1', 'ball'])\n",
      "print(df2.ix['sent2', 'ball'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also call them by their row and column indices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df1.ix[0,0])\n",
      "print(df1.ix[1,0])\n",
      "print(df2.ix[0,0])\n",
      "print(df2.ix[1,0])\n",
      "print(df2.ix[0])\n",
      "print(df2.index)\n",
      "print(df2.columns)\n",
      "print(df2.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, what can we do with this?  We can use, e.g., the correlation metric in Pandas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.irow(0).corr(df2.irow(1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, if we have the `scikit-learn` package, there is a lot more we can do.</br>\n",
      "__Note: to install scikit-learn on Linux with Python 3.4, use the following command:</br>\n",
      "`sudo pip3 install git+https://github.com/scikit-learn/scikit-learn.git`.__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also measure the distance between two documents with the `pairwise_distances` function in `sklearn`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import pairwise_distances\n",
      "euclid = pairwise_distances(df2) #Euclidean distance between the two documents.\n",
      "print(euclid)\n",
      "df_euclid = pd.DataFrame(data = euclid, index = df2.index, columns = df2.index)\n",
      "print(df_euclid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But raw counts of words are not the best way to weight the words in a document.</br>\n",
      "One better, and widely accepted, way is the _tf-idf_ metric  _Tf-idf_ stands for 'term frequency-inverse document frequency'.  It weights the importance each word has for each document based on how often it occurs in the document and the inverse of how many documents contain it in the corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tfidf = TfidfTransformer().fit_transform(df2)\n",
      "print(tfidf)\n",
      "df_tfidf = pd.DataFrame(data = tfidf.toarray(), index = df2.index, columns = df2.columns)\n",
      "print(df_tfidf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's compare the euclidean distance between the _tf-idf_ weighted documents instead of using the raw word counts, as we did above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_euclid = pairwise_distances(df_tfidf) #Euclidean distance between the two documents.\n",
      "df_tf_euclid = pd.DataFrame(data = tf_euclid, index = df2.index, columns = df2.index)\n",
      "print(df_tf_euclid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now it's your turn.  There are several text files in the `data` sub-directory in the present directory.  Construct a term-document matrix made up of the term-document vectors for each individual document.</br>\n",
      "Then you should construct a _tf-idf_ matrix based on the raw count vector you just constructed.</br>\n",
      "Then use at least 5 of the `pairwise_distance` metrics from __sklearn__ to evaluate the distance between the individual documents.</br>\n",
      "And, finally, save all of your matrices, both the count matrices and the _tf-idf_ matrices as .txt files in a `results` sub-directory in this directory.\n",
      "Put your code in the box below or in a separate .py file. __If you do the latter, please make sure that you put your code in a place and give it a name so that I can find it.__"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Put your code here."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you have your (at least 5) _tf-idf_ matrices, take a look at them and compare them.  Do any of the metrics stand out as being better for certain evaluative purpose?  If so, which metrics and for which purposes.</br>\n",
      "__Write your answer in this text box below this line.__</br>\n",
      "_Your answer_</br>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}